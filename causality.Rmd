---
title: "Causal Inference"
author: "yamaguchi"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
   df_print: "paged"  
   use_bookdown: TRUE 
   fig_caption: yes  
   number_sections: FALSE 
   css: custom_style2.css  
header-includes:
   - \usepackage{amsmath}
   - \usepackage{nccmath}
number_sections: true
bibliography: reference.bib   
csl: "primates.csl"
---

```{r, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE, fig.align = "left",
                      cache = TRUE)
```

# 本稿の目的  
本稿では、統計的因果推論の理論とRでの実装についてまとめる。統計的因果推論には大きく分けて潜在的結果変数の枠組みを用いる**Rubin流**(星野, 2009; 高橋, 20212)と**構造的因果モデル(SCM: Structual Causal Model)**と**因果ダイアグラム(もしくはグラフィカルモデル)**を用いる**Pearl流**に分けられる。本稿では、主に後者に焦点を当てて解説を行う。  

参考にした書籍やウェブサイトは、以下のものである。  

- Causal inference in statistics: A primer (邦訳「入門統計的因果推論」)[@Pearl2016]   
  $\rightarrow$ 本稿のベース      

- The book of why: the new science of cause and effect. (邦訳「因果推論の科学」)[@Pearl2018]  
  $\rightarrow$ 一般向け書籍。数式を用いない解説や事例が豊富。因果推論の科学ができるまでの歴史についても学べる。  

- 岩波データサイエンス vol. 3 因果推論ー実世界のデータから因果を読む (岩波データサイエンス慣行委員会, 2016)  
  $\rightarrow$ バックドア基準をはじめ因果推論のトピックに関する短くわかりやすい解説        

- 統計的因果推論―回帰分析の新しい枠組み― (宮川, 2004)  

- Take a Risk: 林岳彦の研究メモ [ウェブサイト](https://takehiko-i-hayashi.hatenablog.com/)  


# 0. パッケージの読み込み   
因果ダイアグラムの分析には主に`dagitty`パッケージ[@Textor2016]を、描画には'dagitty'をベースに作られた`ggdag`パッケージ[@Barrett2018]を用いる。  

それぞれの関数の使い方は以下のサイトを参照。  
[dagitty](http://www.dagitty.net/)  
[ggdag](https://rdrr.io/cran/ggdag/man/ggdag-package.html)  

```{r, cache = FALSE}
library(tidyverse)
library(dagitty)
library(ggdag)
library(patchwork)
library(easystats)
library(GGally)
library(ppcor)
library(ggsci)
```

<br />

# 1 なぜ統計的因果推論が必要か  
私たちが研究を行う上で立てるリサーチクエスチョンの多くは、「ニホンザルの群れの凝集性はオスの攻撃に<u>影響を受けるのか</u>」、「食物状況はオスの性行動に<u>影響しているか</u>」というようなものである。これらの問いは、2つ(あるいはそれ以上)の変数間の**相関関係**(「$X$が小さい/大きいほど、$Y$も小さい/大きい」)ではなく、**因果関係**(「$X$を小さく/大きく<u>すると</u>、$Y$も小さく/大きく<u>なる</u>」)に関する問いである。すなわち、私たちの研究の多くは、データから変数間の因果関係(およびその効果量)を推測する(= **統計的因果推論**)ことがゴールにある。よって、どのようにすれば因果推論を行うことができるかを学ぶことは、私たちの研究の根本にかかわる重要なことだと考えられる。    

**統計的因果推論**についての知識がなければ、実際に得られたデータから因果関係を推測することは難しい。特に研究者が変数への操作や介入を行えない観察研究では、複数の要因が複雑に影響し合っていることが珍しくないため、殊更に困難である。そのような状況では、変数間でみられる**相関関係が実際の因果関係と一致しない**ことが良く起こるからである。  


以下の例を考えてみよう。  
ニホンザルのコドモにおいて、ある期間に食べた1日当たりの**平均食物摂取量**(乾燥重量で$X$g)がその期間における**遊び時間割合**($Y$%)に影響しているかを調べたいとする。$X$と$Y$、そして**年齢**($Z$)の間に図\@ref(fig:fig-graph)の間のような因果関係があるとする(もちろん架空の関係である)。なお、丸は各変数を、矢印は因果関係を表す(詳細は次章を参照)。    

```{r fig-graph, echo = FALSE, fig.dim = c(2.1,2.1), fig.cap = "X, Y, Zの間の因果関係"}
dagify(X ~ Z,
       Y ~ Z,
       Y ~ X,
       coords = tibble(name = c("X","Z","Y"),
                       x = c(1,2,3),
                       y = c(1,1.3,1))) %>% 
  ggdag(node_size =10, text_size = 3)+
  geom_text(data = tibble(x = c(1.4,2,2.65),y =c(1.15,1.015,1.15),label = c("+","+","－"),
                          xend = c(1.4,2,2.65), yend = c(1.15,1.015,1.15), size = 1.5),
            aes(label = label))+
  theme_dag()
```

このような関係の下ではどのようなデータが得られるだろうか。シミュレーションによって図\@ref(fig:fig-graph)のような因果関係を持つデータを生成し(詳細はRのコードを参照)、$X$と$Y$の関係を散布図にしたものが、図\@ref(fig:fig-example)である。  
この図からは「食物摂取量($X$)が多いほど、遊び時間割合($Y$)が**少ない**」という負の相関関係が読み取れる。この関係は、「食物摂取量($X$)が多くなると、遊び時間割合($Y$)が**多くなる**」という実際の因果関係(図\@ref(fig:fig-graph)参照)とは正負が逆になってしまっている。つまり、$X$と$Y$の相関関係だけを見るだけでは、その因果関係を適切に推測できないのである。  

```{r fig-example, echo = FALSE, fig.cap = "平均食物摂取量(X)と遊び時間割合(Y)の関係。直線は回帰直線を表す。", fig.dim = c(3.2,3.2)}
set.seed(123)
## データ数
N <- 48
## 年齢
Z <- rep(1:4, each = N/4) 
## 食物量  
X <- rnorm(N, 120 + 20*Z, 10)
## 5遊び時間割合  
Y <- rnorm(N, 25 -10*Z + 0.2*X , 5)

d <- tibble(X=X,Y=Y,Z=Z)

## 図
d %>% 
  ggplot(aes(x=X, y=Y))+
  geom_point(alpha = 0.7, size = 1.3)+
  geom_smooth(method = "lm",
              se = F,
              size = 1.2,
              color = "grey60")+
  theme_bw(base_size = 10)+
  theme(aspect.ratio = 0.8)
```

なぜこのようなことが起こるのだろうか。それは、$X$と$Y$の因果関係を適切に推測するためには、その両方に影響している第3の変数$Z$(**年齢**)を考慮しなくてはならないからである。年齢ごとに$X$と$Y$の関係を見てみると、実際の因果関係と一致した方向の正の相関(「$X$が多いほど$Y$も多い」)が確認できるようになる。  

```{r fig-example2, echo = FALSE, fig.cap = "年齢(Z)を考慮した平均食物摂取量(X)と遊び時間割合(Y)の関係。直線は年齢ごとの回帰直線を表す。", fig.dim = c(4,3.2)}
d %>% 
  ggplot(aes(x=X, y=Y, color = as.factor(Z)))+
  geom_point(alpha = 0.7, size = 1.3)+
  geom_smooth(method = "lm",
              se = F,
              size = 0.8)+
  labs(color = "年齢(Z)")+
  scale_color_nejm()+
  theme_bw(base_size = 10)+
  theme(aspect.ratio = 0.8)
```

このように、データの背後にある変数間の**因果構造**(= データ生成過程)を考慮しなければ、データから適切な因果推論を行うことはできない。  
この後見ていくように、データの因果構造によってどのような変数を考慮すべきかは異なってくる。本稿では、**構造的因果モデル(SCM)**と**因果ダイアグラム**という2つのツールを用いることで、いかなる因果構造を持つデータについても適切に因果推論を行う手法を学んでいく。  

学ぶのは主に以下の3点についてである。  

- 因果関係を正確に記述する方法(第2章)  
- 因果モデルの構造をデータの特徴に関連付ける方法(第3章)  
- モデルとデータに含まれる因果関係の組み合わせから結論を導く方法(第4~5章)  

<br />

# 2. 構造的因果モデルと因果ダイアグラムの基礎          
## 2.1 構造的因果モデル(SCM)  
変数間の因果関係を記述するためには、データセットにある変数間の因果関係についての仮定を正式に記述する必要がある。  
そこで、**構造的因果モデル(SCM: Structural Causal Model)**を導入する。  
SCMは、以下の3つによって記述される。   

- $V$: その変動理由がモデル内で記述される変数(**内生変数**)の集合    
- $U$: その変動理由がモデル内で記述されない変数(**外生変数**)の集合   
- $F$: モデル内の他の変数によって内生変数の値を決定する関数の集合  


内生変数は**少なくとも1つの外生変数を含む関数を用いて記述**される(=少なくとも1つの外生変数の子孫である)。一方で、外生変数は**他の変数によって記述できない**(=他の変数の子孫ではない)。すなわち、すべての外生変数の値が分かれば、関数$F$により全ての内生変数の値が正確に決定される。    

例: 教育レベル($X$)と職務経験($Y$)による給料($Z$)  

$U = \lbrace X, Y \rbrace, V = \lbrace Z \rbrace, F = \lbrace f_Z \rbrace$  
$$
\begin{aligned}
  f_Z: Z &= 2X + 3Y
\end{aligned}
$$

**因果の定義**[@Pearl2016]    
SCM内で$Y$の値を決定する関数に$X$が使われるとき、$X$は$Y$の**直接原因**であるという。$X$が$Y$の直接原因であるか、$Y$の原因の直接原因であるとき、$X$**は**$Y$**の原因である**という。上の例では、$X$**と**$Y$**は**$Z$**の直接原因**である。 

**ひとことメモ**  
因果関係の定義には様々な流儀があり、ここではPearl et al. (2016)の定義を紹介した。 
前述の定義とほとんど同じであるが、林・黒木(2016)は以下のように定義している。  

> 「要因$X$を人為的に変化させた(介入した)とき、要因$Y$も変化する」とき「要因$X \rightarrow Y$の因果関係がある」と呼ぶ  


## 2.2 因果ダイアグラムの概要  
因果ダイアグラムとは、図\@ref(fig:fig-graph)のように**丸(記号は何でもよいが)と矢印を用いて変数間の因果構造を表したもの**である。矢印は**因果関係**を表し、それぞれのSCMには対応する因果ダイアグラムが必ず存在する。因果ダイアグラムを活用することで、定量的なデータに依ることなくモデルの中に存在する変数の関係を表現することができるので、因果推論を行う上で非常に重要なツールである。  

先ほどの例を因果ダイアグラムで表すと以下のようになる。  

```{r, echo = FALSE, fig.dim = c(2.5,2), fig.cap = "因果ダイアグラムの例"}
dagify(Z ~ X,
       Z ~ Y,
       coords = tibble(name = c("X","Z","Y"),
                       x = c(1,2,3),
                       y = c(1.2,1,1.2))) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```


## 2.3 因果ダイアグラムの描き方  
ここでは、Rでの因果ダイアグラムの描き方を解説する。  
まずはノード(点)の名前と位置(x,y座標)を記したデータフレーム(あるいはtibble)を作成する。  
```{r}
dag1 <- tibble(name = c("A","B","C","D"),
               x = c(1, 2, 3, 2),
               y    = c(2, 2, 2, 1))
```

その後、`gadify()`でノード間の関係を記述する。  

- `y ~ x`は`y <- x`を表す。  
- `x1 ~~ x2`は `x1 <-> x2`を表す。  

```{r}
dagified_dag1 <- dagify(A ~ B,
                      C ~ B,
                      D ~ A + C,
                      ##暴露変数の指定ができる    
                      exposure = "C",
                      ## 結果変数の指定ができる  
                      outcome = "D",
                      coords = dag1)
```

グラフの描画に必要な情報が書き込まれるよう。  
```{r}
dagified_dag1
```

`tidy_dagitty()`でデータフレームの形で出力もできる。  
```{r}
tidy_dagitty(dagified_dag1)
```

最後に、`ggplot()`を用いてダイアグラムを描画する。  
`ggdag`パッケージに含まれる関数を使用する。  
```{r fig-sample, fig.dim = c(3.5,2.3), fig.cap = "作成した因果ダイアグラム \\label{fig_sample}"}
ggplot(dagified_dag1,
       aes(x = x, y=y, xend = xend, yend = yend))+
  ## ノード、文字、エッジの設定。Dのみ色を変える 
  geom_dag_point(aes(color = name == "D"),
                 alpha = 1/2, size = 10.5, show.legend = F)+
  geom_dag_text(color = "black")+
  geom_dag_edges()+
  scale_color_manual(values = c("steelblue", "orange"))+
  ## 座標を消す
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_minimal() +
  theme(panel.grid = element_blank())
```

特にこだわりがなければ、`ggdag()`で容易に描ける。  
`theme_dag()`で最小限のテーマ(目盛や背景を削除)にしてくれる。  
```{r,fig.dim = c(3,2.5), fig.cap = "ggdag()で描いた因果ダイアグラム"}
ggdag(dagified_dag1, node_size =10, text_size = 3)+
  theme_dag()
```

## 2.4 因果ダイアグラムの基礎    
有向辺(方向のあるエッジ)の始点を**親**、終点を**子**と呼ぶ。  
```{r, echo = FALSE,fig.dim = c(3,1.5), fig.cap = "ノードの親子"}
dagify(B ~ A,
       coords = tibble(name = c("A","B"),
               x = c(1, 2),
               y    = c(1, 1))) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()+
  coord_cartesian(ylim = c(0,2))+
  annotate(geom = "text",
           x = c(1,2), y = c(1.6,1.6), label = c("親","子"))
  
```


また、3つ以上のノードがあり、2つの有向辺が共に入ってくるノードや、2つの有向辺が共に出ていくノードがない場合(下図のようなとき)、これを**有向道**と呼ぶ。  
有向道上の最初のノードは、道上のすべてのノードの**祖先**である(下図で、CはAの**祖先**、AはCの**子孫(=孫)**である)。  

```{r, echo = FALSE,fig.dim = c(3,1.5), fig.cap = "ノードの親・子・孫"}
dag2 <- tibble(name = c("A","B","C"),
               x = c(1, 2, 3),
               y    = c(1, 1, 1))

dagify(B ~ A,
       C ~ B,
       coords = dag2) %>% 
  ggdag(node_size =10, text_size = 3)+
  coord_cartesian(ylim = c(0,2))+
  theme_dag()+
  annotate(geom = "text",
           x = c(1,2,3), y = c(1.6,1.6,1.6), label = c("親","子","孫"))
```

Rでは、`dagitty`パッケージでこれを求められる。  
図\@ref(fig:fig-sample)の因果ダイアグラムを用いて求めてみる。  

**親**  
```{r}
## 親
parents(dagified_dag1,"D")

## 子
children(dagified_dag1, "B")

## 祖先
ancestors(dagified_dag1, "D")

## 子孫
descendants(dagified_dag1, "B")
```

また、**特定の2つのノード間の有向道**は以下のように求められる。  
`directed = F`とすると有向道以外の道も調べられる。  
```{r}
paths(dagified_dag1, "B", "D", directed = T)$path
```

有向道があるノードからスタートして、それ自身に戻ってくるとき、その道とグラフは**巡回的**という。  
例えば、以下の二つのグラフは巡回的である。  
巡回的でないグラフを**非巡回的**であるという。  
```{r, echo = FALSE,fig.dim = c(5,2.5), fig.cap = "巡回的なグラフの例"}
dag3 <- tibble(name = c("B","A","C"),
               x = c(1, 2, 3),
               y    = c(1, 2, 1))

dagify(B ~ A,
       C ~ A,
       C ~ B,
       coords = dag3) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()-> g_dag3_a

dagify(B ~ A,
       A ~ C,
       C ~ B,
       coords = dag3) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag() -> g_dag3_b

g_dag3_a + g_dag3_b
```


## 2.5 独立と従属  
2つの変数$X$と$Y$は、以下が成り立つときにそれぞれがとりうる全ての値$x$と$y$について**独立**という。すなわち、XとYが独立のとき、変数Yの値がなんであろうと、$P(X = x)$の値は変わらない(**= 相関がない**)。    

$$
P(X = x|Y = y) = p(X = x)
$$

独立は記号を用いて以下のように表せる。  

$$
X \mathop{\perp\!\!\!\!\perp}  Y
$$

また、確率変数$Z$の任意の値が与えられたときに$X$と$Y$が全ての$x$、$y$について独立のとき、$X$と$Y$は$Z$の下で**条件付き独立**であるという。  
以下のようにあらわす。  

$$
X \mathop{\perp\!\!\!\!\perp}  Y|Z
$$

因果ダイアグラム上で独立または条件付き独立であるノードは、`impliedConditionalIndependencies()`を用いて以下のように求められる(例. 図\@ref(fig:fig-sample)について)。  
```{r}
impliedConditionalIndependencies(dagified_dag1)
```

なお、独立でない2変数は**従属**であるという。  

**ひとことメモ**  
実際の分析では、例えば以下のような場合に$Z$**について条件付け**したことになる。  

- ある$Z$の値のデータのみを抽出して分析する  
- 偏相関係数: $Z$の影響を排除して他の2変数相関係数を算出する    
- 回帰分析: 説明変数に$Z$を加えて回帰分析を行う  

<br />

# 3. 因果ダイアグラムの因果推論への応用  
この章では、因果ダイアグラムを因果推論へ応用する方法を学ぶ。  
具体的には、以下の手順によって仮定した因果モデル(SCM)が正しいものか検証することになる。    

1. あるSCMと因果ダイアグラムが正しいと仮定したとき、変数間の独立/従属関係がどのようになるかを調べる(3.1~3.2)          
2. 実際のデータにおける独立/従属関係が、仮定した因果ダイアグラムから想定される独立/従属関係と一致するか確認することで、SCMで仮定した因果関係が正しいかを検証し、必要な場合は修正する(3.3)  

## 3.1 因果ダイアグラムの基本3パターン  
まず、因果ダイアグラムに現れる基本3パターンをまとめる。実際の因果ダイアグラムはより複雑だが、どのようなダイアグラムも基本的にはこの3パターンの因果構造の組み合わせで表すことができる。    

本節では**それぞれのパターンで、どのようなときに因果ダイアグラムに含まれる2変数が独立/従属になるか**を学ぶ。これによって以下のことが可能になる。  

- 相関(あるいは従属)$\neq$因果になるのがどのようなときなのかを理解できるようになる    
- いかなる因果ダイアグラムにおいても、変数間の独立/従属関係を知ることができるようになる    

## 3.1.1 連鎖経路(chain)  
### 3.1.1.1 概要  
図\@ref(fig:fig-chain)のように3つのノードと2つのエッジがあり、中央の変数に1つのノードが入ってきて、また別のノードがそこから出ていく構成を**連鎖経路(chain)**と呼ぶ。  

- $X$と$Y$は$Z$の原因である  
- $Y$を$X \rightarrow Z$の因果関係における**中間変数**(あるいは**媒介因子**)という    


```{r}
dag4 <- tibble(name = c("X","Y","Z"),
               x = c(1.5, 2, 2.5),
               y    = c(2.5, 2, 1.5))

dagified_chain <- dagify(Y ~ X,
       Z ~ Y,
       coords = dag4)
```

```{r fig-chain,fig.dim = c(2.5,2), fig.cap = "連鎖経路の例", echo = FALSE}
dagified_chain %>% 
  ggdag(node_size =10, text_size = 3)+
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_minimal()+
  theme(panel.grid = element_blank())
```

連鎖経路では以下が成り立つ。  

1. $X$と$Y$、$Y$と$Z$、$X$と$Z$は特異な例を除けばそれぞれ従属である    
2. $X$**と**$Z$**は、**$Y$**の下で条件付き独立**  

2は、$Y$**で条件づけると、因果関係がある**$X$**と**$Y$**の関連が消えてしまう**ことを示している。  
2はRでも確かめられる。  
```{r}
impliedConditionalIndependencies(dagified_chain)
```


### 3.1.1.2 連鎖経路の例  
2は以下のような例で確かめられる。  
$X$、$Y$、$Z$の間に以下のような関係(SCM)が成り立つとする。   
ただし、$U_x$、$U_y$、$U_z$は平均0で標準偏差1の正規分布に従い、互いに独立とする(以後同様)。  

$$
\begin{aligned}
  X &= U_x\\
  Y &= \frac{4}{5}X + U_y\\
  Z &= \frac{2}{3}Y + U_z\\
\end{aligned}
$$

上記のSCMは以下のようにも書き換えられる。  
なお、$X \sim Normal(0,1)$は$X$が平均0,標準偏差1の正規分布に従うことを表す。$i = 1, 2, ...,N$である。  
$$
\begin{aligned}
  x_{i} &\sim Normal(0,1) \\
  y_{i} &\sim Normal(\frac{4}{5}x_{i},1) \\
  z_{i} &\sim Normal(\frac{2}{3}y_{i},1) \\
\end{aligned}
$$

実際にデータを生成して分析してみる。  
```{r}
N <- 10000 
Ux <- rnorm( N ); Uy <- rnorm( N ); Uz <- rnorm( N )
X <- Ux
Y <- 4/5*X + Uy
Z <- 2/3*Y + Uz
d <- data.frame(X=X,Y=Y,Z=Z)
```

$X$、$Y$、$Z$は互いに有意に相関している($X$,$Y$,$Z$**は互いに従属**)。  
```{r, fig.dim = c(5,3.5), fig.cap = "連鎖経路におけるX, Y, Zの間の関係"}
ggpairs(d)
```

回帰分析($Z \sim X$)をすると、$X$と$Z$は有意に関連している($X$**と**$Z$**は従属**)。
```{r}
model_parameters(lm(Z~X,d)) %>% 
  print_md()
```

しかし、**説明変数に**$Y$**も加えると(=**$Y$**で条件づけると)**、$X$の係数はほぼ0になり、因果関係がある$X$と$Z$の関連は消失してしまう($X$**と**$Z$**は、Yの下で条件付き独立** )。  

▶ $Y$**の値が分かれば、**$Z$**を予測するうえで**$X$**の値は関係なくなるから**($X$は$Y$通してしか$Z$に影響を与えていないので)      
```{r}
model_parameters(lm(Z~X+Y,d)) %>% 
  print_md()
```

なお、XとYの間の有向道が1つだけあり、それが連鎖経路であるとき、$X$**と**$Y$**はその間のいずれの変数(1つでなくともよい)についても条件付き独立**である。すなわち、下図で$X$と$W$は$Y$と$Z$いずれでの下でも条件付き独立になる。    

```{r,fig.dim = c(3,2.5), echo = FALSE,  fig.cap = "連鎖経路の例2"}
dag4_b <- tibble(name = c("X","Y","Z","W"),
               x = c(1.5, 2, 2.5,3),
               y    = c(2.5, 2, 1.5,1))

dagified_chain_b <- dagify(Y ~ X,
       Z ~ Y,
       W ~ Z,
       coords = dag4_b) 
  
dagified_chain_b %>% 
  ggdag(node_size =10, text_size = 3)+
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_minimal()+
  theme(panel.grid = element_blank())
```


## 3.1.2 分岐経路(fork)  
### 3.1.2.1 概要  
図\@ref(fig:fig-fork)のように、2つの変数に共通の変数が影響を与えているような構成を**分岐経路(fork)**と呼ぶ。またこのとき、$X$を**交絡因子(変数)**と呼ぶ。  

```{r}
dag5 <- tibble(name = c("X","Y","Z"),
               x = c(2, 1, 3),
               y    = c(2, 1, 1))

dagify(Y ~ X,
       Z ~ X,
       coords = dag5) -> dagified_fork
```

```{r fig-fork, fig.dim = c(2,2), fig.cap = "分岐経路の例", echo = FALSE}
dagified_fork %>% 
  ggdag(node_size =10, text_size = 3)+
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_minimal()+
  theme(panel.grid = element_blank()) 
```

分岐経路では以下が成り立つ。  

1. $X$と$Y$、$X$と$Z$、$Y$と$Z$は特異な例を除けばそれぞれ従属    
2. $Y$**と**$Z$**は**$X$**の下で条件付き独立**  

1は、**交絡因子によって因果関係にない**$Y$**と**$Z$**の間に関連(相関)が生じてしまう**ことを示している。  
2は、この関連は$X$で条件づけることによって消失することを示す。  
これはRでも確かめられる。  
```{r}
impliedConditionalIndependencies(dagified_fork)
```

### 3.1.2.2 分岐経路の例  
2を直観的に確かめるため、以下の例を考える。  
$X$、$Y$、$Z$の間に以下のような関係(SCM)が成り立つと、$X$、$Y$、$Z$の関係は分岐経路で表せる。   

- $X$(＝気温)が$Y$(= アイスクリームの売上)と$Z$(= プール来場者数)に影響  
- $Y$と$Z$は互いに影響しない    

$$
\begin{aligned}
  X &= U_x\\
  Y &= \frac{5}{2}X + U_y\\
  Z &= \frac{2}{3}X + U_z\\
\end{aligned}
$$

上記のSCMは以下のようにも書ける。  
ただし、$i = 1,2,...N$。  
$$
\begin{aligned}
  x_{i} &\sim Normal(0,1) \\
  y_{i} &\sim Normal(\frac{5}{2}x_{i},1) \\
  z_{i} &\sim Normal(\frac{2}{3}x_{i},1) \\
\end{aligned}
$$

SCMをもとに実際にデータを生成してみる。  
```{r}
N <- 10000 
Ux <- rnorm( N ); Uy <- rnorm( N ); Uz <- rnorm( N )
X <- Ux
Y <- 5/2*X + Uy
Z <- 2/3*X + Uz
d <- data.frame(X=X,Y=Y,Z=Z)
```

$X$、$Y$、$Z$は互いに有意に強く相関している(**=**$X$,$Y$,$Z$**は互いに従属している**)。  
```{r,fig.dim = c(5,3.5), fig.cap = "分岐経路におけるX, Y, Zの間の関係"}
ggpairs(d)
```

回帰分析($Z \sim Y$)をすると、$Y$と$Z$は有意に関連している($Y$**と**$Z$**は従属**)。  
```{r}
model_parameters(lm(Z~Y,d)) %>% 
  print_md()
```

しかし、**説明変数に**$X$**も加えると(=**$X$**で条件づけると)**、$Y$の係数はほぼ0になり、$Y$と$Z$の関連は消失する(**=**$Y$**と**$Z$**は**$X$**の下で条件付き独立**)。すなわち、交絡が解消された。      
```{r}
model_parameters(lm(Z~X+Y,d)) %>% 
  print_md()
```


## 3.1.3 合流点(collider)  
### 3.1.3.1 概要  
図\@ref(fig:fig-collider)のようにあるノードに他の2つのノードからエッジが入ってきている構成を**合流点(collider)**と呼ぶ。  
```{r}
dag5 <- tibble(name = c("X","Z","Y"),
               x = c(1, 2, 3),
               y    = c(2, 1, 2))

dagify(Z ~ X,
       Z ~ Y,
       coords = dag5) -> dagified_collider
```

```{r fig-collider, fig.dim = c(2,2), echo = FALSE, fig.cap = "合流点の例"}
dagified_collider %>% 
  ggdag(node_size =10, text_size = 3)+
  scale_x_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(.1, .1)) +
  theme_minimal()+
  theme(panel.grid = element_blank()) 
```

合流点では以下が成り立つ。  

1. $X$と$Z$、$Y$と$Z$は特異な例を除けばそれぞれ従属    
2. $X$と$Y$は独立  
3. $X$**と**$Y$**は**$Z$**の下で条件付き従属**    

1は自明であり、2もRで確かめられる。  
```{r}
impliedConditionalIndependencies(dagified_collider)
```

### 3.1.3.2 合流点の例1  
1と2は直観的に理解できるが、3が成り立つのはなぜだろうか？  
以下の例を考える。  
<br />  

ある大学の入学試験で以下のように合否を判定するとする  

- 音楽試験の点数($X$)と学力試験の点数($Y$)の合計点で合否($Z$、$X+Y > 115$なら合格)を判定  
- $X$と$Y$には全く関連がない  
- $U_X$と$U_y$はそれぞれ平均50、標準偏差10の正規分布に従う  

$$
\begin{aligned}
  X &= U_x\\
  Y &= U_y\\
  Z &= \left\{
  \begin{array}{ll}
  1(合格) & (X + Y > 115)\\
  0(不合格) & (X + Y < 115)
  \end{array}
       \right.
\end{aligned}
$$

上記のSCMは以下のように書き換えられる。  
ただし、$i = 1,2,...N$。  
$$
\begin{aligned}
  x_{i} &\sim Normal(50,10) \\
  y_{i} &\sim Normal(50,10) \\
  z &= \left\{
  \begin{array}{ll}
  1(合格) & (x_{i} + y_{i} > 115)\\
  0(不合格) & (x_{i} + y_{i} < 115)
  \end{array}
       \right.
\end{aligned}
$$

実際にこれに基づいてデータを生成して分布をみてみると、1と2が確かめられる。  

- 合格者($Z=1$)の方が不合格者($Z=0$)より、$X$と$Y$がそれぞれ大きい($X$と$Z$、$Y$と$Z$は従属)  
- $X$と$Y$には相関がない(独立)。  

```{r}
N <- 500 
Ux <- rnorm(N, mean = 50, sd = 10); Uy <- rnorm(N, mean = 50, sd = 10); Uz <- rnorm( N )
X <- Ux
Y <- Uy

Z <- vector()

for(i in 1:500){
if (X[i] + Y[i] > 115){
  Z[i] <- "1"
  }else{
  Z[i] <- "0" 
 }
}

d <- data.frame(X=X,Y=Y,Z=Z)
```

```{r,fig.dim = c(5,3.5), fig.cap = "合流点を含む経路におけるX, Y, Zの間の関係"}
ggpairs(d)
```

ここで、$Z$で条件付けるとどうなるだろうか。例えば、合格者($Z=1$)のデータのみを抽出したとする。  
青い直線は合格者のみのデータを抽出したときの回帰直線である。このとき、因果会計にない$X$と$Y$の間に相関が生じていることが分かる(= $X$**と**$Y$**は**$Z$**の下で条件付き従属**)。これを**合流点バイアス**という。    

```{r, echo = FALSE,fig.dim = c(4.5,3), fig.cap = "合流点バイアスの例"}
d %>% 
  mutate(Z = str_replace_all(Z,pattern = c("1"="合格","0" = "不合格"))) %>% 
  ggplot(aes(x = X, y = Y))+
  geom_point(aes(fill = Z),
             shape = 21,size = 3, alpha = 0.7,
             color = "black")+
  scale_fill_manual(values = c("white","black"))+
  geom_smooth(data = . %>% filter(Z == "合格"),
              method = "lm",
              color = "blue",
              se = F)+
  geom_abline(slope = -1,
              intercept = 115,
              linetype = "dashed",
              color = "red2")+
  annotate(geom = "text",
           x = 35, y = 85,
           label = "X + Y = 115",
           color = "red2")+
  theme_bw(base_size = 16)+
  labs(fill = "")
```

### 3.1.3.3 合流点の例2  
なお、合流点だけでなく、**合流点の子孫のいずれを条件した場合でも**、独立した変数同士が従属になることがある。  
以下の例を考える。<br />    

交尾期において、各観察日にニホンザルの群れに訪れる群れ外オスの数($Z$)は、その日の発情メスの数($X$)と気温($Y$)によって決まるとする。  
また、メスがオスから攻撃される頻度($W$)は、その日に群れを訪れた群れ外オスの数($Z$)に依存するとする。  
以下のSCMを考える。  

$$
\begin{aligned}
  x_{i} &\sim Poisson(3.5)\\
  y_{i} &\sim Normal(10,1.5)\\
  z_{i} &\sim Poisson(0.8x_{i}+0.75y_{i}-2)\\  
  w &\sim Normal(0.4z_{i} + 1.2, 0.5)
\end{aligned}
$$

SCMを因果ダイアグラムで表すと以下のようになる。  

```{r, fig.dim = c(2,2.3), fig.cap = "合流点の例2"}
dag6 <- tibble(name = c("X","Z","Y","W"),
               x = c(1, 2, 3,2),
               y    = c(2, 1.5, 2,1))

dagify(Z ~ X,
       Z ~ Y,
       W ~ Z,
       coords = dag6) -> dagified_collider_b
  
dagified_collider_b %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```

実際にこれに基づいてデータを生成して分布をみてみると、$X$と$Y$に有意な相関はない(=独立である)ことが確かめられる。また、$Z$と$W$はどちらも$X$, $Y$と有意な相関がある(=従属)。  
```{r}
set.seed(191)

N <- 500 
X <- rpois(N, 3.5)
Y <- rnorm(N, 10, 1.5)
Z <- rpois(N, 0.8*X + 0.75*Y - 2)
W <- rnorm(N, 0.4*Z+1.2, 0.5)

d <- data.frame(X=X,Y=Y,Z=Z,W=W)
```

```{r,fig.dim = c(5.5,4), fig.cap = "合流点の子を含む経路におけるX, Y, Z, Wの間の関係"}
ggpairs(d)
```

一方、$Z$またはその子孫である$W$を統制した場合の$X$と$Y$の偏相関係数を調べると、いずれも小さいが有意な相関が現れる(**=条件付き従属**)。  

$Z$**を統制**  
```{r, cache = FALSE}
pcor.test(d$X,d$Y,d$Z)
```

$W$**を統制**  
```{r, cache = FALSE}
pcor.test(d$X,d$Y,d$W)
```

## 3.2 d分離性(d-separation)  
一般的な因果モデル(ダイアグラム)は、以上で見た3つのパターンより複雑であることが多い。具体的には、多くのモデルにおいて変数間を結ぶ道は複数存在し、それぞれの道は様々な連鎖、分岐、合流点を通過している。  
ここでは、このように複雑なモデルにおいても変数間の独立/従属を判断するため、前節までに学んだことをもとに**d-分離(d-separation)**という概念を導入する。**２つのノード(変数)がd分離されるとき、それらの変数は独立である**といえる。    

**d分離の定義**  
以下の1または2が成り立つとき、グラフ上で道$p$がノードの集合$Z$に**ブロックされている**という。  

1. $p$は連鎖経路$A \rightarrow B \rightarrow C$または分岐経路$A \leftarrow B \rightarrow C$を含み、中央のノードが$Z$に含まれる(= $B$について条件付けしている)  
2. $p$は合流点$A \rightarrow B \leftarrow C$を含み、合流点$B$とその全ての子孫が$Z$に含まれない(= $Z$とその子孫で条件付けしない)　　

$Z$が$X$と$Y$の間の道をすべてブロックするとき、$Z$**が与えられた下で**$X$と$Y$**はd分離しているという**。
一方で、$X$と$Y$がd分離されていないとき、$X$と$Y$は**d連結である**という。    

例1. 合流点とその子、分岐点を持つ因果ダイアグラム  
```{r}
dag7 <- tibble(name = c("X","Z","Y","W","Uz","Uw","Ux","Uy","U","Uu"),
               x = c(3, 1, 4,2,1,2,3,4,2,0.5),
               y = c(3,3,3,2,4,3.5,4,4,1,1.5))

dagify(X ~ Ux,
       Z ~ Uz,
       Y ~ X + Uy,
       W ~ Z + Uw + X,
       U ~ W + Uu,
       coords = dag7) -> dagified_dsep1
```

```{r fig-dsep,fig.dim = c(3.5,3), fig.cap =　"合流点とその子、分岐点を持つ因果ダイアグラム", echo = FALSE}
dagified_dsep1 %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```

- $Z$と$Y$を結ぶ道は合流点 $W$を含むのでブロックされている(= d分離されている) が、$W$について条件付けすると、$Z$と$Y$はd連結になる(= 従属)。これは、$W$の子である$U$について条件付けしても同様。  
- しかし、$W$に加えて$X$も条件付けすると、$W \leftarrow X \rightarrow Y$の分岐経路がブロックされるので、$Z$と$Y$はd分離されたままである。 

Rでは、$Z$と$Y$がそれぞれの変数で条件づけられたときにd分離されるかを以下のように調べられる。  
```{r}
## Wで条件付け
dseparated(dagified_dsep1, "Z","Y", "W")

## WとXで条件付け  
dseparated(dagified_dsep1, "Z","Y", c("W","X"))
```

例2. 図\@ref(fig:fig-dsep)に$Z$と$Y$の間の分岐経路を加えたもの  
```{r}
dag8 <- tibble(name = c("X","Z","Y","W","Uz","Uw","Ux","Uy","U","Uu","T","Ut"),
               x = c(3, 1, 4,2,1,1.8,2.25,4,2,0.5,2.5,2.5),
               y = c(3.3,3,3,2,4,3.2,3.2,4,1,1.5,4,4.5))

dagify(T ~ Ut,
       X ~ Ux,
       Z ~ T + Uz,
       Y ~ X + T + Uy,
       W ~ Z + Uw + X,
       U ~ W + Uu,
       coords = dag8) -> dagified_dsep2
```

```{r,fig.dim = c(4.5,4.2), fig.cap = "先のグラフにZとYの間の分岐経路を加えたもの", echo = FALSE}
dagified_dsep2 %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```

- $Z$と$Y$の間に分岐経路ができたことで、何も条件付けなければ$Z$と$Y$は従属になる(= d連結)。  
- $T$について条件付ければ、$Z$と$Y$の間の道はブロックされ、d分離される。  
- $T$に加えて$W$について条件づけると、$Z \leftarrow T \rightarrow Y$はブロックされるが、$Z \rightarrow W \leftarrow X \rightarrow$は開いてしまうので、d連結になる。  
- さらに$X$も加えて条件付けすれば、再びd分離される。  

Rでも確かめられる。  
```{r}
## Tで条件付け
dseparated(dagified_dsep2, "Z","Y", "T")

## TとWで条件付け  
dseparated(dagified_dsep2, "Z","Y", c("T","W"))

## T, W, Xで条件付け  
dseparated(dagified_dsep2, "Z","Y", c("T","W","X"))
```

**練習問題**  

> 1. 図\@ref(fig:fig-prac1)で隣接していない変数の組それぞれについて、どの変数の集合で条件付き独立となるか     

```{r fig-prac1,  echo = FALSE,fig.dim = c(3,2.5), fig.cap = "練習問題1の因果ダイアグラム"}
dagified_prac1 <- dagify(T~S+U,
       S~R,
       R~X,
       U~V,
       Y~V,
       coords = tibble(name = c("Y","V","U","T","S","R","X"),
                       x = c(1,2,3,4,5,6,7),
                       y = c(1,2,1,2,1,2,1))) 
  
dagified_prac1 %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```


A. 答えは以下の8通りである。  

- $Y$, $V$, $U$は分岐経路であり、$Y$と$U$を結ぶ道は1つしかないので、$Y \mathop{\perp\!\!\!\!\perp}  U|V$      
- $V$, $U$, $T$は連鎖経路であり、$V$と$T$を結ぶ道は1つずつしかないので、$V \mathop{\perp\!\!\!\!\perp}  T|U$   
- $X$, $R$, $S$, $T$は連鎖経路であり、道は一つしかない。よって、$X \mathop{\perp\!\!\!\!\perp}  T|R, X \mathop{\perp\!\!\!\!\perp}  T|S, X \mathop{\perp\!\!\!\!\perp}  S|R, R \mathop{\perp\!\!\!\!\perp}  T|S$  
- $V$は$Y$と$T$のいずれの原因にもなっているので、$Y$と$T$はおそらく従属である。しかし、$U$で条件づけると$V$と$T$が独立になり、結果的に$V$の子である$Y$と$T$も独立になる($Y \mathop{\perp\!\!\!\!\perp}  T|U$)    
- $V$で条件づけると$Y$と$U$が独立になり、結果的に$U$の子である$T$も$Y$と独立になる($Y \mathop{\perp\!\!\!\!\perp}T|U$)  

Rでは、すべての独立/条件付き独立の変数の集合は以下のように求められる。  
```{r}
# impliedConditionalIndependencies(dagified_prac1)
```

> 2. 図\@ref(fig:fig-prac1)のモデルからデータを生成し、線形方程式$Y = a + bX + cZ$をあてはめる。傾きbを0にするには$Z$にどの変数を選べばよいか。      

A. $Z$の下で$X$と$Y$が条件付き独立(d分離)になればよい。$T$以外は条件づけてもd分離されるので、$T$以外ならどれでもよい。    
```{r}
## 各変数で条件づけたときにXとYがd分離されるか調べる  
sapply( names(dagified_prac1), function(Z) dseparated(dagified_prac1,"X","Y",Z) )
```

実際にモデルからデータを生成して確認する。  
```{r}
d_prac1 <- simulateSEM(dagified_prac1,
                       # パス係数を0.7に設定する 
                       b.lower = 0.7,
                       b.upper = 0.7,
                       N = 5000)
```

確かに$T$で条件づけると$X$の係数は0でない。  
```{r}
lm(Y ~ X + T, data = d_prac1) %>% 
  model_parameters() %>% 
  print_md()
```

他の変数(例えば$S$や$V$)ではほぼ0になる。  
```{r}
lm(Y ~ X + S, data = d_prac1) %>% 
  model_parameters() %>% 
  print_md()
```

```{r}
lm(Y ~ X + V, data = d_prac1) %>% 
  model_parameters() %>% 
  print_md()
```

> 3. 図\@ref(fig:fig-prac2)で隣接していない変数の組それぞれについて、どの変数の集合で条件付き独立となるか  

```{r fig-prac2,  echo = FALSE, fig.dim = c(3,2.5),fig.cap = "練習問題3の因果ダイアグラム"}
dagified_prac2 <- dagify(T~S+U,
       S~R,
       R~X,
       U~V,
       Y~V,
       P ~ T,
       coords = tibble(name = c("Y","V","U","T","P","S","R","X"),
                       x = c(1,2,3,4,4,5,6,7),
                       y = c(1,2,1,2,1,1,2,1))) 
  
dagified_prac2 %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```

A. 問1で挙げた組み合わせに加えて、以下でも条件付き独立になる。  

- $P\mathop{\perp\!\!\!\!\perp}U|T$ (連鎖経路)    
- $P\mathop{\perp\!\!\!\!\perp}V|T, P\mathop{\perp\!\!\!\!\perp}V|U$ (連鎖経路)  
- $P\mathop{\perp\!\!\!\!\perp}S|T$ (連鎖経路)  
- $P\mathop{\perp\!\!\!\!\perp}R|S, P\mathop{\perp\!\!\!\!\perp}R|T$ (連鎖経路)  
- $P\mathop{\perp\!\!\!\!\perp}X|R,P\mathop{\perp\!\!\!\!\perp}X|S, P\mathop{\perp\!\!\!\!\perp}X|T$ (連鎖経路)  
- $P\mathop{\perp\!\!\!\!\perp}Y|V,P\mathop{\perp\!\!\!\!\perp}Y|U, P\mathop{\perp\!\!\!\!\perp}Y|T$ (分岐経路+連鎖経路)  

以下でも確かめられる。  
```{r}
#impliedConditionalIndependencies(dagified_prac2)
```

> 4. 図\@ref(fig:fig-prac2)のモデルで、方程式$Y = a + bX + cR + dS + eT + fP$をあてはめると、どの係数が0になるか。 

A. $X,R,S,T,P$について、これらの変数が全て条件づけられたときに$Y$とd分離されるかを検討すればよい。$T$と$S$を除けばd分離されるので、係数が0になるのはそれらの変数である。  
```{r}
dseparated(dagified_prac2, "Y", list(), c("X","R","S","T","P"))
```

実際にモデルからデータを生成して確認する。  
たしかに、$T$と$S$以外は係数がほぼ0になる。  
```{r}
d_prac2 <- simulateSEM(dagified_prac2,
                       # パス係数を0.7に設定する 
                       b.lower = 0.7,
                       b.upper = 0.7,
                       N = 5000)

lm(Y ~ X + R + S + T + P, data = d_prac2) %>% 
  model_parameters() %>% 
  print_md()
```

> 5. 以下のダイアグラムについて、隣接しないノード全ての組について、その2つをd分離する変数の集合を答えよ(最小限必要な変数のみでよい)。  

```{r, echo = FALSE}
dag9 <- tibble(name = c("X","Y","Z1","Z2","Z3","W"),
               x = c(1,3,1,3,2,2),
               y = c(1,1,3,3,2,1))

dagify(X ~ Z1 + Z3,
       Z3 ~ Z1 + Z2,
       Y ~ Z2 + Z3 + W,
       W ~ X,
       coords = dag9) -> dagified_prac3
```

```{r fig-prac3, fig.dim = c(2.5,2), fig.cap = "練習問題5の因果ダイアグラム", echo = FALSE}
dagified_prac3 %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```

A. 以下の通り  

- $X$と$Y$: $\{ W, Z3, Z1 \},\{ W, Z3, Z2 \}$    

▶ $X$と$Y$の間の道をブロックするため、$W$$とZ3$は必ず入れる必要あり。しかし$Z3$(= 合流点)を入れると$X \leftarrow Z1 \rightarrow Z3 \leftarrow Z2 \rightarrow Y$がブロックされなくなるため、加えて$Z1$または$Z2$も条件づける必要がある。  

- $Y$と$Z1$: $\{ Z3, Z2, X \}, \{ Z3, Z2, W \}$    

▶ $Z1 \rightarrow Z3 \rightarrow T$と$Z1 \rightarrow X \rightarrow W \rightarrow Y$をブロックするため$Z3$と$X$または$W$は必ず条件づける必要あり。しかし$Z$を条件づけると$Z1 \rightarrow Z3 \leftarrow Z2 \rightarrow Y$がブロックされなくなるため、$Z2$も条件づける必要がある。  

- $X$と$Z2$: $\{ Z1, Z3 \}$    
- $W$と$Z2$: $\{ X \}$, $\{ Z3, Z1 \}$    
- $W$と$Z1$: $\{ X \}$  
- $W$と$Z3$: $\{ X \}$    

以下でも確かめられる。  
```{r}
#impliedConditionalIndependencies(dagified_prac3)
```

> 6. 図\@ref(fig:fig-prac3)のモデルで$Z3$の値から$Z2$の値を予測する。$W$の値も使った方がよりよい予測になるか？  

一般に、$Z2$とd分離されていない(= 独立でない)限りは、どの変数を入れても予測は向上する。しかし、$W$は$Z3$で条件づけたとき$Z2$とd分離されるため、$W$を入れても予測は良くならないはずである。  

これは以下のシミュレーションでも確かめられる。  
```{r}
d_prac3 <- simulateSEM(dagified_prac3,
                       # パス係数を0.4に設定する 
                       b.lower = 0.4,
                       b.upper = 0.4,
                       N = 10000)


## Z3のみ
m_without_W <- lm(Z2 ~ Z3, data = d_prac3)

## Z3 + W
m_with_W <- lm(Z2 ~ Z3 + W, data = d_prac3)

## Z3 + Y
m_with_Y <- lm(Z2 ~ Z3 + Y, data = d_prac3)
```

線形モデルの決定係数$R^2$を計算すると、$W$を入れても入れなくてもほとんど変わらないことが分かる。  
一方、$Z3$とd連結している(従属な)$Y$を入れると予測は向上する。  
```{r}
## 決定係数を比較
compare_performance(m_without_W,m_with_W, m_with_Y) %>% 
  data.frame() %>% 
  dplyr::select(1,7,8) %>% 
  print_md()
```

## 3.3 モデル検定と因果探索  
実際の分析では、**モデルから想定される条件付き独立が実際のデータでも見られるかによって、因果モデルが正しいものかを検証**していく。  
たとえば、図\@ref(fig:fig-prac3)では$W$と$Z_{1}$は$X$によりd分離されている。よって、もしこの因果モデルが正しいとすれば、以下の式で回帰分析を行ったときに、係数$R_1$は0になるはずである。  

$$
w = r_{X}x + r_{1}Z_{1}
$$

もし$r_1$が0でないならば、因果モデルは間違っていることになる。また、真のモデルでは$W$と$Z_1$の間に$X$ではd分離されていない道があるはずだということになる。  
このように、モデルにある全てのd分離の条件がデータの条件付き独立と一致するかを検討することで、モデルの検証を行える。  

d分離性を利用したモデルの検証には以下の利点がある。  

- 変数の関係を表す関数がどのような形でもグラフの構造の実から検証可能(ノンパラメトリック)  
- 局所的なモデルの修正を行える  

なお、最終的には1つではなく、複数のモデルまでしか絞り込めないのことの方が多い。これは、データにある独立性/従属性と矛盾しないような因果モデルは複数存在する場合が多いからである。このようなモデルは**marcov equivalent**であるという。  

例えば、以下のグラフで表されるモデルは全てmarcov equivalentである。  
`ggdag_equivalent_dags()`を用いて求められる。  
```{r,fig.cap = "Marcov equivalentなモデルの例",fig.dim = c(4.5,4.5)}
dagify(X ~ Z1,
       Z2 ~ Z1,
       Y ~ Z2 + W + X,
       W ~ X ) -> dagified_prac4

ggdag_equivalent_dags(dagified_prac4,node_size =9, text_size = 3)+
  theme_dag()
```

**練習問題**  

> 1. 図\@ref(fig:fig-prac3)のモデルで、もしいずれかの係数が0でないときにモデルが誤りになる$Y$の回帰式を１つ書け    

たとえば、図\@ref(fig:fig-prac3)のモデルで$X$と$Y$は$Z_2,Z_3,W$によってd分離される。よって、以下の回帰式で$X$の係数が0でなければモデルは誤りになる。  

$$
Y = a + bX + cZ_1 + dz_3 + eW 
$$
実際、モデルから生成したデータを用いて分析すると$X$の係数はほぼ0になる。  
```{r}
lm(Y ~ X + Z2 + Z3 + W, data = d_prac3) %>% 
  model_parameters() %>% 
  print_md()
```

> 2. 図\@ref(fig:fig-prac3)のモデルで、$X$が観測されていない場合に、もしいずれかの係数が0でないときにモデルが誤りになる$Z_3$の回帰式を１つ書け  

$X$が未観測のとき、条件付き独立になるのは以下の場合である。  
$Z_3$と独立な変数はないため、係数が0になるような変数はない。  
```{r}
## xが未観測であることにする  
latents(dagified_prac3) <- "X"
impliedConditionalIndependencies(dagified_prac3)
```

> 3. 図\@ref(fig:fig-prac3)のモデルで問1のような回帰式がいくつあればモデルを完全に検証したことになるか。  

このような回帰式の集合は**basis set**と呼ばれ、以下のように求められる。  
最後の2つは同じ2変数についてのものなので、4つの回帰式を検証すればよい。  
```{r}
## Xが未観測という情報を消す
latents(dagified_prac3) <- c()

impliedConditionalIndependencies(dagified_prac3, type = "basis.set")
```

例えば、一行目は以下の回帰式で検証できる。  
$$
W = a + bX + cZ_1 + dZ_2 + eZ_3 
$$

実際、モデルから生成したデータを用いて分析すると$Z_1, Z_2, Z_3$の係数はほぼ0になる。  
```{r}
lm(W ~ X + Z1 + Z2 + Z3, data = d_prac3) %>% 
  model_parameters() %>% 
  print_md()
```

<br />

# 4. 介入効果の推定  
ここでは、いよいよ相関関係と因果関係をきちんと見分け、原因を変化させたときに結果に与える効果(**因果効果・介入効果**)の大きさを推定するための方法を学ぶ。  

これまで見てきたように、変数間に相関関係があるからと言って、因果関係があるとは限らない場合が多々ある。よって、**相関関係から予測される効果**が**実際の介入効果(因果効果)**とズレることがよく起こる。  

例えば、あなたは河川中の汚染物質量が底生昆虫の種数に与える影響を知るため、データを収集したとする。その結果、図\@ref(fig:fig-cor)のようなデータが得られた($X$: 河川中の汚染物質の量, $Y$: 底生昆虫の種数)。このデータだけをもとに、「底生昆虫の種数を増やすためには、河川中の汚染物質を減らすべきだ」と結論付けることはできるだろうか？  

答えはノーである。あくまでもこのデータから言えるのは、「$X$が小さいほど$Y$は大きい」ということだけであり、これは**相関関係**の話である。あなたが本当に知りたいのは「$X$を**<u>小さくしたときに</u>、$Y$**が大きくなる**」といえるかである。  

```{r, echo = FALSE}
N <- 100
Z <- rep(c(0,1),each = N/2)
X <- rnorm(N, 20 - 12*Z,4)
Y <- rnorm(N, 10 + 7*Z, 2.5)
d <- tibble(X =X, Y=Y,Z=Z)
```

```{r fig-cor, echo = FALSE, fig.cap = "河川中の汚染物質量と底生昆虫の種数の関係",fig.dim = c(3,3)}
ggplot(d,aes(x=X,y=Y))+
  geom_point()+
  geom_smooth(method = "lm", se = F, color = "grey")+
  theme_bw(base_size = 12)+
  theme(aspect.ratio = 1)
```

例えば、各データが川の上流域/下流域のいずれで収集されたかも記録し、図\@ref(fig:fig-cor2)のような結果が得られたとする。このグラフから、データを上流/下流で収集するかが$X$と$Y$の両方に独立に影響したことで、$X$と$Y$の相関が生じた可能性が示唆される(交絡要因の影響)。このように、$X$と$Y$の相関が$X$と関係ない要因で生じているなら、$X$を変化させても$Y$は変化しないだろう。  

```{r fig-cor2, echo = FALSE, fig.cap = "データ収集場所の情報も含めた河川中の汚染物質量と底生昆虫の種数の関係",fig.dim = c(4,3)}
d %>% 
  mutate(Z = str_replace_all(Z, c("1" = "下流域","0"="上流域"))) %>% 
  ggplot(aes(x=X,y=Y))+
  geom_point(aes(color = Z))+
  geom_smooth(aes(color = Z), method = "lm", se = F, color = "grey")+
  theme_bw(base_size = 12)+
  theme(aspect.ratio = 1)+
  labs(color = "")
```

図\@ref(fig:fig-cor3)のように、$Y$はデータ収集場所の影響もうけるが、それに加えて$X$の影響も部分的に受けているということもあるかもしれない(上流域/下流域それぞれでも$X$と$Y$に相関がある)。その場合、$X$を変化させれば$Y$も部分的に変化する。    
```{r, echo = FALSE}
N <- 100
Z <- rep(c(0,1),each = N/2)
X <- rnorm(N, 20 - 12*Z,4)
Y <- rnorm(N, 10 + 2.5*Z - 0.7*X, 3.5)
d2 <- tibble(X =X, Y=Y,Z=Z)
```

```{r fig-cor3, echo = FALSE,fig.cap = "データ収集場所の情報も含めた河川中の汚染物質量と底生昆虫の種数の関係2",fig.dim = c(4,3)}
d2 %>% 
  mutate(Z = str_replace_all(Z, c("1" = "下流域","0"="上流域"))) %>% 
  ggplot(aes(x=X,y=Y))+
  geom_point(aes(color = Z))+
  geom_smooth(aes(color = Z),method = "lm", se = F, color = "grey")+
  theme_bw(base_size = 12)+
  theme(aspect.ratio = 1)+
  labs(color = "")
```

このように、$X$の介入効果を推定するためには、$Y$**の値がどのような過程で得られるのかに大きく依存**するのである。  

介入効果を推定するために良く用いられる方法は、**ランダム化比較試験(RCT)**である。この方法では、応答(反応)変数($Y$)に影響を与える因子は、1つ($X$)を除いて固定されるか、ランダム化される。このようなとき、$Y$の変化は$X$によってのみ生じたといえるので、$X$の介入効果を正確に推定できる。  

しかし、実際の研究ではRCTを行うことは不可能であることが多い(金銭的・時間的・倫理的・方法論的問題などなど...)。そのような場合、研究者は代わりにこうした操作を行わない観察研究を行うことになるが、近年の統計学の発展により、**観察研究であっても適切に分析を行えば介入効果を推定できる**ことが分かってきた。以下では、前章までに学んだことをもとに、どうすれば観察研究でも介入効果を正確に推定できるのかを学んでいく。  

## 4.1 介入とは    
モデルにおいてある変数に「介入する」とは、その変数をある値に固定することを意味する($\neq$条件付けする)。よって、しばしば他の変数の値も変化する。一方で、値を固定するので、**他の変数からの影響はなくなる**。  

グラフでは、$X$に介入するということは、$X$に向かう辺が全て取り除かれることを表す(図\@ref(fig:fig-kainyu)のAからBに変化するように)。このことからも、$X$で条件するときとは変数間の関係が全く違くなることが分かる。$X$にある変数に介入する際の手順は、因果グラフの構造により異なる。      

**ひとことメモ**  
$X$以外をランダム化することも、$X$へ向かう辺をすべて取り除くことに相当する。  
```{r fig-kainyu, fig.cap = "Xに介入したときのグラフの変化", echo = FALSE,fig.dim = c(4.5,2.8)}
dag10 <- tibble(name = c("X","Ux","Z","Uz","Y","Uy"),
               x = c(1,1,2,2,3,3),
               y = c(1,1.5,1.5,2,1,1.5))

dagify(X ~ Ux + Z,
       Z ~ Uz,
       Y ~ Uy + X + Z,
       coords = dag10) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()+
  labs(title = "A")-> p_dag1

dag11 <- tibble(name = c("X","Z","Uz","Y","Uy"),
               x = c(1,2,2,3,3),
               y = c(1,1.5,2,1,1.5))

dagify(X ~ X,
       Z ~ Uz,
       Y ~ Uy + X + Z,
       coords = dag11) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()+
  labs(title = "B") -> p_dag2


p_dag1 + p_dag2
```

条件付き確率($P(Y = y|X = x)$)と区別するため、$X$をある値$x$に固定(= $X$に介入)したときに$Y = y$になる確率は、以下のように書く。  
$do$表記と因果ダイアグラムを用いることで、グラフが現実を正確に表現していれば、観察データのみから介入効果を推定することができる。  

$$
P(Y = y|do(X = x))
$$


## 4.2 調整  
### 4.2.1 調整と調整化公式  
それでは、$P(Y = y|do(X = x))$はどのように求めたらよいだろうか。  
図\@ref(fig:fig-chousei)で、$Z$は性別、$X$は薬の投与の有無(0/1)、$Y$は回復の有無(0/1)を表すとする。  
```{r fig-chousei, fig.cap = "薬の効果を表す因果ダイアグラム", echo = FALSE,fig.dim = c(2.3,2.3)}
dag10 <- tibble(name = c("X","Ux","Z","Uz","Y","Uy"),
               x = c(1,1,2,2,3,3),
               y = c(1,1.5,1.5,2,1,1.5))

dagify(X ~ Ux + Z,
       Z ~ Uz,
       Y ~ Uy + X + Z,
       coords = dag10) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```


患者全員に薬を投与する($do(X = 1$))という介入と、誰にも薬を投与しないという介入($do(X = 0$)との比較を考える。このとき、その差は因果効果差または平均因果効果(ACE: average causal effect)と呼ばれ、以下の式で表せる。$X$と$Y$が複数の値をとる場合は、すべての組み合わせついて効果を算出する。    

$$
P(Y = 1|do(X = 1)) - P(Y =1| do(X=0))
$$

因果効果$P(Y = y|do(X = x))$は、介入して$X$への辺を取り除いたモデル(図\@ref(fig:fig-chousei2))における条件付確率$P_m(Y=y|X=x)$に等しい[^foot1]。  

[^foot1]: 介入前と介入後のモデルにおける確立を区別するため、介入後のモデルの確立にはmを添え字として付す。  

```{r fig-chousei2, fig.cap = "介入後の因果ダイアグラム", echo = FALSE, fig.dim = c(2.3,2.3)}
dag11 <- tibble(name = c("X","Z","Uz","Y","Uy"),
               x = c(1,2,2,3,3),
               y = c(1,1.5,2,1,1.5))

dagify(X ~ X,
       Z ~ Uz,
       Y ~ Uy + X + Z,
       coords = dag11) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```

また、介入前と介入後のグラフにおける確率について、以下の2点が成り立つ。    

1. $Z$を決める過程は$Z$から$X$への矢印がなくなっても変わらないので、周辺確率$P(Z = z)$は介入後も変化しない($P(Z=z) = P_m(Z=z)$)。  

2. $Y$が$X$と$Z$によって決まる過程(つまり$Y = f(x,y,u_y)$)は$X$への介入によって変わるわけではない。よって、条件付き確率$P(Y=y|X=x,Z=z) = P_m(Y=y|X=x,Z=z)$である。  

加えて、介入後のグラフで$X$と$Z$はd分離されて独立なので、$P_m(Z=z|X=x) = P_m(Z=z)$も成り立つ(3)。  

以上より、因果効果$P(Y=y|do(X=x))$は以下のように変形できる。  

$$
\begin{aligned}
  &P(Y=y|do(X=x))\\
  &= P_m(Y=y|X=x)\\
  &= \sum_{z}P_m(Y=y|X=x,Z=z)P_m(Z=z|X=x) (全確率の公式より)\\  
  &= \sum_{Z}P_m(Y=y|X=x,Z=z)P_m(Z=z) (1より)\\
  &= \sum_{z}P(Y=y|X=x,Z=z)P(Z=z) (2と3より)
\end{aligned}
$$

この式により、因果効果を介入前のグラフのデータから計算できるようになる。  
この式は**調整化公式**と呼ばれ、ある$Z$の値について$X$と$Y$の関係を計算し、それを$Z$について平均していることが分かる。このような処理を「$Z$**による調整**」または「$Z$についてのコントロール」と呼ぶ。  
  
**調整化公式の使用例**:   
図\@ref(fig:fig-chousei)のグラフについて、以下のデータ(表\@ref(tab:tab-chosei))が得られているとする。  

```{r tab-chosei, echo = FALSE}
data1 <- tribble(
  ~"",      ~"薬投与",             ~"薬投与なし", 
  "男性",   "81/87が回復(93%)",    "234/270が回復(87%)",
  "女性",    "192/263が回復(73%)", "55/80が回復(69%)",
  "全体",   "273/350が回復(78%)", "289/350が回復(83%)"
)

knitr::kable((data1), booktabs = TRUE,
caption = '薬の投与に関する結果')
```

このとき、平均因果効果(ACE)は以下のように求められる。なお、$X=1$は薬が投与されたこと、$Z=1$は患者が男であること、$Y=1$は患者が回復したことを表す。  
ACEは正の値なので、薬の効果があったことを示す。  

$$
\begin{aligned}
  &P(Y = 1| do(X = 1))\\
  &= P(Y=1|X=1,Z=1)P(Z=1) + P(Y=1|X=1,Z=0)P(Z=0) \\
  &= 0.93 \times \frac{87+270}{700} + 0.73 \times \frac{263+80}{700}\\
  &= 0.832\\
\end{aligned}
$$

$$
\begin{aligned}
  &P(Y = 1| do(X = 0))\\
  &= P(Y=1|X=0,Z=1)P(Z=1) + P(Y=1|X=0,Z=0)P(Z=0) \\
  &= 0.87 \times \frac{87+270}{700} + 0.69 \times \frac{263+80}{700}\\
  &= 0.7818\\
  \\
  &\therefore ACE = P(Y = 1| do(X = 1)) - P(Y = 1| do(X = 0))\\
  &= 0.832 - 0.7818 = 0.0502\\
\end{aligned}
$$

### 4.2.2 何を調整すべきか  
注意すべき点は、モデルの因果構造によって、調整すべき変数の集合$Z$が異なる点である。  
例えば、因果ダイアグラムが図\@ref(fig:fig-chosei3)のような事例を考える($X$: 薬の投与, $Y$: 回復, $Z$: 血圧)。  

```{r fig-chosei3, fig.cap = "薬の効果を表す因果ダイアグラム", echo = FALSE, fig.dim = c(2.3,2.3)}
dag12 <- tibble(name = c("X","Z","Y"),
               x = c(1,1.5,2),
               y = c(1,1.5,1))

dagify(Z ~ X,
       Y ~ X + Z,
       coords = dag12) %>% 
  ggdag(node_size =10, text_size = 3)+
  theme_dag()
```

このモデルについて、因果効果$P(Y = 1| do(X = 1))$を求めたいとする。このとき、$Z$で調整すべきだろうか？  
$X$への介入とは、$X$に向かう辺をすべて取り除くことであった。よって、もしこの因果ダイアグラムが正しいのであれば、$Z$で調整する必要はなく、以下の等式が成り立つ。  

$$
P(Y=1|do(X=1)) = P(Y=1|X=1)
$$

## 4.3 バックドア基準  
それでは、どの変数を変数の集合$Z$に含めて調整すれば因果効果を適切に吸い愛知できるだろうか。  
その基準として最も重要なものが**バックドア基準**である。


# References  
林岳彦・黒木学 (2016). 相関と印が止まると矢印のはなし 初めてのバックドア基準. 岩波データサイエンス刊行委員会(編) 岩波データサイエンス Vol. 3 (pp. 28-48) 岩波書店  
星野崇宏(2009)「調査観察データの統計科学：因果推論・選択バイアス・データ融合」岩波書店  
宮川雅巳 (2004). 統計的因果推論―回帰分析の新しい枠組み― 朝倉書店  
高橋将宜 (2022). 統計的因果推論の理論と実装. 共立出版  

